{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce1969eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e80b3acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/asehgal/Downloads\n"
     ]
    }
   ],
   "source": [
    "cd Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c686bf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data-set(2).csv\" ,sep=',')\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5b25863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>Actions</th>\n",
       "      <th>FilePath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>PREVIEW</td>\n",
       "      <td>/Shared/Sample Docs/CIMs/CIM-03-Bar-Wash.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>DOWNLOAD</td>\n",
       "      <td>/Shared/Sample Docs/CIMs/CIM-01-Consolidated-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>PREVIEW</td>\n",
       "      <td>/Shared/Sample Docs/CIMs/CIM-02-American-Casi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>ADD_FILE</td>\n",
       "      <td>/Shared/Sample Docs/CIMs/CIM-06-Pizza-Hut.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>ADD_FILE</td>\n",
       "      <td>/Shared/Sample Docs/CIMs/CIM-04-Alcatel-Lucen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>5.0</td>\n",
       "      <td>ADD_FILE</td>\n",
       "      <td>/Shared/Sample Docs/Term Sheets/ILPA-Model-LP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>1.0</td>\n",
       "      <td>DOWNLOAD</td>\n",
       "      <td>/Shared/Sample Docs/Term Sheets/TERM_SHEET_EQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>6.0</td>\n",
       "      <td>PREVIEW</td>\n",
       "      <td>/Shared/Sample Docs/Term Sheets/ILPA-Model-LP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>8.0</td>\n",
       "      <td>DOWNLOAD</td>\n",
       "      <td>/Shared/Sample Docs/Term Sheets/ILPA-Model-LP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>5.0</td>\n",
       "      <td>ADD_FILE</td>\n",
       "      <td>/Shared/Sample Docs/Term Sheets/CIIE Term She...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>659 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     UserId    Actions                                           FilePath\n",
       "0       7.0    PREVIEW       /Shared/Sample Docs/CIMs/CIM-03-Bar-Wash.pdf\n",
       "1       8.0   DOWNLOAD   /Shared/Sample Docs/CIMs/CIM-01-Consolidated-...\n",
       "2       5.0    PREVIEW   /Shared/Sample Docs/CIMs/CIM-02-American-Casi...\n",
       "3       7.0   ADD_FILE      /Shared/Sample Docs/CIMs/CIM-06-Pizza-Hut.pdf\n",
       "4       1.0   ADD_FILE   /Shared/Sample Docs/CIMs/CIM-04-Alcatel-Lucen...\n",
       "..      ...        ...                                                ...\n",
       "654     5.0   ADD_FILE   /Shared/Sample Docs/Term Sheets/ILPA-Model-LP...\n",
       "655     1.0   DOWNLOAD   /Shared/Sample Docs/Term Sheets/TERM_SHEET_EQ...\n",
       "656     6.0    PREVIEW   /Shared/Sample Docs/Term Sheets/ILPA-Model-LP...\n",
       "657     8.0   DOWNLOAD   /Shared/Sample Docs/Term Sheets/ILPA-Model-LP...\n",
       "658     5.0   ADD_FILE   /Shared/Sample Docs/Term Sheets/CIIE Term She...\n",
       "\n",
       "[659 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e78c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def duplicate_rows_randomly(df, n_duplicates, n_delete_actions):\n",
    "    duplicated_rows = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    for user_id in df['UserId'].unique():\n",
    "        user_data = df[df['UserId'] == user_id]\n",
    "\n",
    "        # Duplicate existing rows\n",
    "        for _ in range(n_duplicates):\n",
    "            random_row = user_data.sample(n=1).iloc[0]\n",
    "            duplicated_rows = pd.concat([duplicated_rows, random_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "        # Add 10 random file paths with action value set to \"DELETE\"\n",
    "        for _ in range(n_delete_actions):\n",
    "            random_file_path = \"/Shared/FilePath/\" + ''.join(random.choices('abcdefghijklmnopqrstuvwxyz', k=10)) + \".pdf\"\n",
    "            delete_row = {'UserId': user_id, 'Actions': 'DELETE', 'FilePath': random_file_path}\n",
    "            duplicated_rows = pd.concat([duplicated_rows, pd.DataFrame(delete_row, index=[0])], ignore_index=True)\n",
    "\n",
    "    new_df = pd.concat([df, duplicated_rows], ignore_index=True)\n",
    "    new_df['Actions'] = new_df['Actions'].str.strip()\n",
    "\n",
    "    return new_df\n",
    "new_df = duplicate_rows_randomly(df, n_duplicates=100, n_delete_actions=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e779d6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PREVIEW', 'DOWNLOAD', 'ADD_FILE', 'DELETE'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = new_df\n",
    "df[\"Actions\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71c5fe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_and_fit_algo(df, user_id=None, actions=None, filepath=None):\n",
    "    # If user_id, actions, and filepath are provided, concatenate them to df\n",
    "    if user_id is not None and actions is not None and filepath is not None:\n",
    "        new_data = {'UserId': [user_id], 'Actions': [actions], 'FilePath': [filepath]}\n",
    "        new_df = pd.DataFrame(new_data)\n",
    "        df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "    # Apply label encoding to 'Actions' column\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['Actions_Encoded'] = label_encoder.fit_transform(df['Actions'])\n",
    "    encoded_action = df[df[\"Actions\"] == actions][\"Actions_Encoded\"].values[0]\n",
    "    df[\"Actions\"] = df['Actions_Encoded']\n",
    "    \n",
    "    df = df.drop([\"Actions_Encoded\"], axis = 1)\n",
    "\n",
    "    df['Rating'] = df.groupby(['UserId', 'FilePath'])['FilePath'].transform('count')\n",
    "\n",
    "    # Content-Based Filtering using TF-IDF\n",
    "# Content-Based Filtering using TF-IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df['FilePath'])\n",
    "    cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "    # Collaborative Filtering using Surprise library\n",
    "    reader = Reader(rating_scale=(1, 10))\n",
    "    data_surprise = Dataset.load_from_df(df[['UserId', 'FilePath', 'Rating']], reader)\n",
    "    trainset, testset = train_test_split(data_surprise, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    algo = SVD()\n",
    "    algo.fit(trainset)\n",
    "\n",
    "    return df, algo, cosine_sim, encoded_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4289e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(df, user_id, user_given_file_path, user_actions):\n",
    "    # Call the process_data_and_fit_algo function to preprocess data and fit collaborative filtering algorithm\n",
    "    df, algo, cosine_sim, encoded_action = process_data_and_fit_algo(df, user_id=user_id, actions=user_actions, filepath=user_given_file_path)\n",
    "\n",
    "    # Content-Based Filtering\n",
    "    res = df[df['FilePath'].str.contains(user_given_file_path, case=False, regex=True)].index[0]\n",
    "\n",
    "    sim_scores = list(enumerate(cosine_sim[res]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    excluded_file_path = df['FilePath'].iloc[res]\n",
    "    sim_scores = [i for i in sim_scores if df['FilePath'].iloc[i[0]] != excluded_file_path]\n",
    "\n",
    "    # Select top unique 5 similar files\n",
    "    unique_similar_files = set()\n",
    "    top_similar_files = []\n",
    "    for i in sim_scores:\n",
    "        if df['FilePath'].iloc[i[0]] not in unique_similar_files:\n",
    "            unique_similar_files.add(df['FilePath'].iloc[i[0]])\n",
    "            top_similar_files.append(i)\n",
    "        if len(top_similar_files) == 5:\n",
    "            break\n",
    "\n",
    "    file_indices = [i[0] for i in top_similar_files]\n",
    "    content_based_recommendations = df['FilePath'].iloc[file_indices].tolist()\n",
    "\n",
    "    # Collaborative-Based Filtering\n",
    "    \n",
    "    # collab_based_recommendations = []\n",
    "    # for item in df['FilePath'].unique():\n",
    "    #     predicted_rating = algo.predict(user_id, item).est\n",
    "    #     if predicted_rating > 7.0:\n",
    "    #         collab_based_recommendations.append(item)\n",
    "    \n",
    "    collab_based_recommendations = []\n",
    "\n",
    "    df_small = df[df[\"Actions\"] == encoded_action]\n",
    "    for item in df_small['FilePath'].unique():\n",
    "        # actions_match = set(df[df['FilePath'] == item]['Actions'])\n",
    "        predicted_rating = algo.predict(user_id, item).est\n",
    "\n",
    "        if predicted_rating > 5.0:\n",
    "            collab_based_recommendations.append(item)\n",
    "\n",
    "\n",
    "    return content_based_recommendations, collab_based_recommendations, encoded_action\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c082ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-Based Recommendations for User 1: ['NDA', ' /Shared/Sample Docs/NDA/Bublup_mNDA.docx', ' /Shared/Sample Docs/NDA/Reciprocal NDA.doc', ' /Shared/Sample Docs/NDA/Cocoon Data Holdings Pty Ltd - NDA.docx', ' /Shared/Sample Docs/NDA/Tenna NDA - 2022.doc']\n",
      "Collaborative Filtering Recommendations for User 1: [' /Shared/Sample Docs/CIMs/CIM-06-Pizza-Hut.pdf', ' /Shared/Sample Docs/CIMs/CIM-04-Alcatel-Lucent.pdf', ' /Shared/Sample Docs/CIMs/CIM-02-American-Casino.pdf', ' /Shared/Sample Docs/IMAS/GoldmanSachs - IMA.pdf', ' /Shared/Sample Docs/Investor Suitability Questionnaire/Suitability_Assessment_Form_Corporate.pdf', ' /Shared/Sample Docs/IPSs/IPS - Sample1.pdf', ' /Shared/Sample Docs/IPSs/Sample-Investment-Policy-Statement.pdf', ' /Shared/Sample Docs/LPAs/ILPA-Model-Limited-Partnership-Agreement-WOF.pdf', ' /Shared/Sample Docs/PPMs/PPM-IIFCL-MF-FINAL-23.03.2017-FOR-WEBSITE-1.pdf', ' /Shared/Sample Docs/PPMs/PPM - Blackcommerce LLC.pdf', ' /Shared/Sample Docs/PPMs/private-placement-memorandum.pdf', ' /Shared/Sample Docs/Subscription Agreements/Sample Subscription Agreement.pdf', ' /Shared/Sample Docs/Subscription Agreements/PP Subscription Agreement.pdf', ' /Shared/Sample Docs/Subscription Agreements/ILPA-Model-Subscription-Agreement-Final.pdf', ' /Shared/Sample Docs/Term Sheets/CIIE Term Sheet Template.pdf', ' /Shared/Sample Docs/Term Sheets/ILPA-Model-LPA-Term-Sheet-WOF-Version-1.pdf', ' /Shared/Sample Docs/Term Sheets/Sample Term Sheet.pdf', ' /Shared/Sample Docs/Term Sheets/TERM_SHEET_EQUITY.pdf']\n"
     ]
    }
   ],
   "source": [
    "user_id = 1\n",
    "content_based_recs, collab_based_recs, encoded_action = get_recommendations( df,user_id, \"NDA\",\"DOWNLOAD\")\n",
    "print(f\"Content-Based Recommendations for User {user_id}: {content_based_recs}\")\n",
    "print(f\"Collaborative Filtering Recommendations for User {user_id}: {collab_based_recs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "769bf836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-Based Recommendations for User 1: ['NDA', ' /Shared/Sample Docs/NDA/Bublup_mNDA.docx', ' /Shared/Sample Docs/NDA/Reciprocal NDA.doc', ' /Shared/Sample Docs/NDA/Cocoon Data Holdings Pty Ltd - NDA.docx', ' /Shared/Sample Docs/NDA/Tenna NDA - 2022.doc']\n",
      "Collaborative Filtering Recommendations for User 1: [' /Shared/Sample Docs/CIMs/CIM-02-American-Casino.pdf', ' /Shared/Sample Docs/CIMs/CIM-04-Alcatel-Lucent.pdf', ' /Shared/Sample Docs/CIMs/CIM-06-Pizza-Hut.pdf', ' /Shared/Sample Docs/IMAS/GoldmanSachs - IMA.pdf', ' /Shared/Sample Docs/Investor Suitability Questionnaire/Suitability_Assessment_Form_Corporate.pdf', ' /Shared/Sample Docs/IPSs/IPS - Sample1.pdf', ' /Shared/Sample Docs/IPSs/Sample-Investment-Policy-Statement.pdf', ' /Shared/Sample Docs/LPAs/ILPA-Model-Limited-Partnership-Agreement-WOF.pdf', ' /Shared/Sample Docs/PPMs/PPM-IIFCL-MF-FINAL-23.03.2017-FOR-WEBSITE-1.pdf', ' /Shared/Sample Docs/PPMs/private-placement-memorandum.pdf', ' /Shared/Sample Docs/PPMs/PPM - Blackcommerce LLC.pdf', ' /Shared/Sample Docs/Subscription Agreements/ILPA-Model-Subscription-Agreement-Final.pdf', ' /Shared/Sample Docs/Subscription Agreements/Sample Subscription Agreement.pdf', ' /Shared/Sample Docs/Subscription Agreements/PP Subscription Agreement.pdf', ' /Shared/Sample Docs/Term Sheets/ILPA-Model-LPA-Term-Sheet-WOF-Version-1.pdf', ' /Shared/Sample Docs/Term Sheets/Sample Term Sheet.pdf', ' /Shared/Sample Docs/Term Sheets/CIIE Term Sheet Template.pdf', ' /Shared/Sample Docs/Term Sheets/TERM_SHEET_EQUITY.pdf']\n"
     ]
    }
   ],
   "source": [
    "user_id = 1\n",
    "content_based_recs, collab_based_recs, encoded_action = get_recommendations( df,user_id, \"NDA\",\"PREVIEW\")\n",
    "print(f\"Content-Based Recommendations for User {user_id}: {content_based_recs}\")\n",
    "print(f\"Collaborative Filtering Recommendations for User {user_id}: {collab_based_recs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "019a15d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-Based Recommendations for User 1: ['NDA', ' /Shared/Sample Docs/NDA/Bublup_mNDA.docx', ' /Shared/Sample Docs/NDA/Reciprocal NDA.doc', ' /Shared/Sample Docs/NDA/Cocoon Data Holdings Pty Ltd - NDA.docx', ' /Shared/Sample Docs/NDA/Tenna NDA - 2022.doc']\n",
      "Collaborative Filtering Recommendations for User 1: ['/Shared/FilePath/tdkzxqxsou.pdf', '/Shared/FilePath/kjssfaztst.pdf', '/Shared/FilePath/yaejacmahq.pdf', '/Shared/FilePath/chmhevbxbe.pdf']\n"
     ]
    }
   ],
   "source": [
    "user_id = 1\n",
    "content_based_recs, collab_based_recs, encoded_action = get_recommendations( df,user_id, \"NDA\",\"DELETE\")\n",
    "print(f\"Content-Based Recommendations for User {user_id}: {content_based_recs}\")\n",
    "print(f\"Collaborative Filtering Recommendations for User {user_id}: {collab_based_recs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a9eaea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
